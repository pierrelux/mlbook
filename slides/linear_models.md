---
marp: true
theme: mila
paginate: true
math: mathjax
---

<!-- _class: lead -->

# Mod√®les lin√©aires
## Du risque empirique √† la r√©gularisation bay√©sienne

*Pierre-Luc Bacon*
IFT6390 ‚Äì Fondements de l'apprentissage machine

---

## Plan de la pr√©sentation

1. **Minimisation du risque empirique (MRE)** et pr√©dicteur de Bayes optimal
2. **Moindres carr√©s ordinaires (MCO)** et d√©composition en valeurs singuli√®res (DVS)
3. **Expansion de caract√©ristiques** : du lin√©aire au non lin√©aire
4. **G√©n√©ralisation** : surapprentissage et compromis biais-variance
5. **R√©gression Ridge** : r√©gularisation L2
6. **Cadre probabiliste** : EMV, MAP et lien avec Ridge
7. **Classification lin√©aire** : r√©gression logistique, entropie crois√©e, SGD

---

<!-- footer: "üìñ Chapitre 1 : Le probl√®me d'apprentissage" -->

## Apprentissage supervis√© : le probl√®me

**Donn√©es d'entra√Ænement** : $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N$ tir√©es i.i.d. de $p(\mathbf{x}, y)$

**Objectif** : Trouver une fonction $f \in \mathcal{H}$ qui pr√©dit bien sur de **nouvelles** donn√©es

**Classe d'hypoth√®ses** $\mathcal{H}$, notre espace de recherche :
- Fonctions lin√©aires : $f(\mathbf{x}) = \boldsymbol{\theta}^\top \mathbf{x} + b$
- Polyn√¥mes de degr√© $k$ : $f(x) = \theta_0 + \theta_1 x + \cdots + \theta_k x^k$
- R√©seaux de neurones : $f(\mathbf{x}) = \sigma(\boldsymbol{\Theta}_2 \sigma(\boldsymbol{\Theta}_1 \mathbf{x}))$

Le choix de $\mathcal{H}$ encode nos **hypoth√®ses** sur la forme de la relation entre $\mathbf{x}$ et $y$.

---

## Le risque : ce que nous voulons minimiser

Pour une fonction de perte $\ell(y, \hat{y})$, le **risque** (ou erreur de g√©n√©ralisation) est :

$$\mathcal{R}(f) = \mathbb{E}_{p(\mathbf{x}, y)}[\ell(y, f(\mathbf{x}))] = \int \ell(y, f(\mathbf{x})) \, p(\mathbf{x}, y) \, d\mathbf{x} \, dy$$

Cette quantit√© repr√©sente l'erreur moyenne sur **toutes les donn√©es possibles**, pond√©r√©e par leur probabilit√©.

**Exemples de pertes** :
| Type | Formule | Usage |
|------|---------|-------|
| Quadratique | $\ell(y, \hat{y}) = (y - \hat{y})^2$ | R√©gression |
| 0-1 | $\ell(y, \hat{y}) = \mathbf{1}[y \neq \hat{y}]$ | Classification |

**Probl√®me** : La distribution $p(\mathbf{x}, y)$ est **inconnue**.

---

## Le risque empirique : ce que nous pouvons calculer

Puisque le risque est inaccessible, nous l'**approximons** par la moyenne sur les donn√©es disponibles :

$$\hat{\mathcal{R}}(f, \mathcal{D}) = \frac{1}{N} \sum_{i=1}^{N} \ell(y_i, f(\mathbf{x}_i))$$

| Perte | Risque empirique | Nom usuel |
|-------|------------------|-----------|
| $(y - \hat{y})^2$ | $\frac{1}{N}\sum_i (y_i - f(\mathbf{x}_i))^2$ | Erreur quadratique moyenne |
| $\mathbf{1}[y \neq \hat{y}]$ | $\frac{1}{N}\sum_i \mathbf{1}[y_i \neq f(\mathbf{x}_i)]$ | Taux d'erreur |

**Propri√©t√©** : Par la loi des grands nombres, $\hat{\mathcal{R}}(f) \xrightarrow{N \to \infty} \mathcal{R}(f)$

Le risque empirique est un estimateur **sans biais** du vrai risque.

---

## Principe de minimisation du risque empirique (MRE)

**Id√©e** : Choisir la fonction qui minimise l'erreur sur les donn√©es d'entra√Ænement

$$\hat{f} = \arg\min_{f \in \mathcal{H}} \hat{\mathcal{R}}(f, \mathcal{D}) = \arg\min_{f \in \mathcal{H}} \frac{1}{N} \sum_{i=1}^{N} \ell(y_i, f(\mathbf{x}_i))$$

**Espoir** : Si $\hat{\mathcal{R}}(\hat{f})$ est faible, alors $\mathcal{R}(\hat{f})$ l'est aussi.

**R√©alit√©** : Ce n'est pas toujours le cas. L'√©cart $\mathcal{R}(\hat{f}) - \hat{\mathcal{R}}(\hat{f})$ peut √™tre grand.
- Cet √©cart d√©pend de la **taille** de l'√©chantillon $N$
- Il d√©pend aussi de la **complexit√©** de la classe $\mathcal{H}$
- Ce ph√©nom√®ne s'appelle le **surapprentissage**

---

## Le pr√©dicteur de Bayes optimal

**Question** : Si nous connaissions la vraie distribution $p(\mathbf{x}, y)$, quel serait le meilleur pr√©dicteur?

Le **pr√©dicteur de Bayes optimal** minimise le risque pour chaque $\mathbf{x}$ individuellement :

$$f^*(\mathbf{x}) = \arg\min_{\hat{y}} \mathbb{E}_{p(y|\mathbf{x})}[\ell(y, \hat{y})]$$

Ce pr√©dicteur constitue un **rep√®re th√©orique** : aucun algorithme ne peut faire mieux, car il suppose l'acc√®s √† la vraie distribution conditionnelle $p(y|\mathbf{x})$.

La diff√©rence $\mathcal{R}(\hat{f}) - \mathcal{R}(f^*)$ mesure ce que nous perdons en ne connaissant pas $p$.

---

## Cas de la perte quadratique (L2)

Pour $\ell(y, \hat{y}) = (y - \hat{y})^2$, d√©veloppons l'esp√©rance conditionnelle :

$$\mathbb{E}[(y - \hat{y})^2 | \mathbf{x}] = \mathbb{E}[y^2 | \mathbf{x}] - 2\hat{y}\mathbb{E}[y | \mathbf{x}] + \hat{y}^2$$

Cette expression est une **parabole** en $\hat{y}$ (convexe, car le coefficient de $\hat{y}^2$ est positif).

**Condition d'optimalit√©**, d√©riv√©e nulle :
$$\frac{\partial}{\partial \hat{y}} \mathbb{E}[(y - \hat{y})^2 | \mathbf{x}] = -2\mathbb{E}[y | \mathbf{x}] + 2\hat{y} = 0$$

$$\boxed{\hat{y}^* = \mathbb{E}[y | \mathbf{x}]}$$

**Pour la perte L2, le pr√©dicteur de Bayes optimal est la moyenne conditionnelle.**

---

## Pr√©dicteurs optimaux selon la perte

Chaque fonction de perte d√©finit son propre pr√©dicteur optimal :

| Perte | Formule | Pr√©dicteur optimal |
|-------|---------|-------------------|
| Quadratique | $(y-\hat{y})^2$ | Moyenne : $\mathbb{E}[y\|\mathbf{x}]$ |
| Absolue | $\|y-\hat{y}\|$ | M√©diane : $\text{med}(y\|\mathbf{x})$ |
| 0-1 (classif.) | $\mathbf{1}[y \neq \hat{y}]$ | Mode : $\arg\max_c p(y=c\|\mathbf{x})$ |

**Risque de Bayes**, l'erreur irr√©ductible :
$$\mathcal{R}^* = \mathcal{R}(f^*) = \mathbb{E}[\text{Var}(y | \mathbf{x})]$$

Ce risque repr√©sente le bruit intrins√®que dans les donn√©es. **Aucun algorithme ne peut faire mieux**, peu importe la quantit√© de donn√©es ou la puissance de calcul.

---

<!-- footer: "üìñ Chapitre 2 : R√©gression lin√©aire" -->

## Le mod√®le lin√©aire

Nous cherchons une fonction de la forme :
$$f(\mathbf{x}; \boldsymbol{\theta}) = \boldsymbol{\theta}^\top \mathbf{x} = \sum_{j=1}^{d} \theta_j x_j$$

**Notation matricielle** pour $N$ exemples et $d$ caract√©ristiques :

$$\mathbf{X} = \begin{bmatrix} \mathbf{x}_1^\top \\ \mathbf{x}_2^\top \\ \vdots \\ \mathbf{x}_N^\top \end{bmatrix} \in \mathbb{R}^{N \times d}, \quad \mathbf{y} = \begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_N \end{bmatrix} \in \mathbb{R}^N$$

Les pr√©dictions pour tous les exemples s'√©crivent $\hat{\mathbf{y}} = \mathbf{X}\boldsymbol{\theta}$.

Le biais $b$ peut √™tre absorb√© en ajoutant une colonne de 1 √† $\mathbf{X}$.

---

## Fonction objectif : somme des carr√©s des r√©sidus

Nous voulons minimiser la **somme des carr√©s des r√©sidus** (SCR) :

$$\text{SCR}(\boldsymbol{\theta}) = \sum_{n=1}^{N} (y_n - \boldsymbol{\theta}^\top \mathbf{x}_n)^2 = \|\mathbf{y} - \mathbf{X}\boldsymbol{\theta}\|_2^2$$

En d√©veloppant la norme au carr√© :
$$\text{SCR}(\boldsymbol{\theta}) = (\mathbf{y} - \mathbf{X}\boldsymbol{\theta})^\top(\mathbf{y} - \mathbf{X}\boldsymbol{\theta}) = \mathbf{y}^\top\mathbf{y} - 2\boldsymbol{\theta}^\top\mathbf{X}^\top\mathbf{y} + \boldsymbol{\theta}^\top\mathbf{X}^\top\mathbf{X}\boldsymbol{\theta}$$

Cette fonction est **quadratique convexe** en $\boldsymbol{\theta}$ :
- Terme constant : $\mathbf{y}^\top\mathbf{y}$
- Terme lin√©aire : $-2\mathbf{X}^\top\mathbf{y}$
- Terme quadratique : $\mathbf{X}^\top\mathbf{X}$ (matrice semi-d√©finie positive)

---

## D√©rivation : les √©quations normales

**Gradient** par rapport √† $\boldsymbol{\theta}$ :
$$\nabla_{\boldsymbol{\theta}} \text{SCR} = -2\mathbf{X}^\top\mathbf{y} + 2\mathbf{X}^\top\mathbf{X}\boldsymbol{\theta}$$

**Condition d'optimalit√©**, gradient nul :
$$-2\mathbf{X}^\top\mathbf{y} + 2\mathbf{X}^\top\mathbf{X}\boldsymbol{\theta} = 0$$

$$\mathbf{X}^\top\mathbf{X}\boldsymbol{\theta} = \mathbf{X}^\top\mathbf{y}$$

Ces √©quations sont les **√©quations normales**. Elles expriment que le r√©sidu $\mathbf{r} = \mathbf{y} - \mathbf{X}\boldsymbol{\theta}$ est **orthogonal** √† l'espace colonnes de $\mathbf{X}$ :
$$\mathbf{X}^\top(\mathbf{y} - \mathbf{X}\boldsymbol{\theta}) = \mathbf{0}$$

---

## Solution des moindres carr√©s ordinaires (MCO)

Si $\mathbf{X}^\top\mathbf{X}$ est inversible (rang plein), la solution est :

$$\boxed{\hat{\boldsymbol{\theta}}_{\text{MCO}} = (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\mathbf{y}}$$

**Interpr√©tation g√©om√©trique** :
- $\hat{\mathbf{y}} = \mathbf{X}\hat{\boldsymbol{\theta}}$ est la **projection orthogonale** de $\mathbf{y}$ sur l'espace colonnes de $\mathbf{X}$
- Le r√©sidu $\mathbf{r} = \mathbf{y} - \hat{\mathbf{y}}$ est perpendiculaire √† cet espace
- La **matrice chapeau** $\mathbf{H} = \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top$ projette : $\hat{\mathbf{y}} = \mathbf{H}\mathbf{y}$

**Complexit√©** : $O(Nd^2 + d^3)$, domin√©e par l'inversion de $\mathbf{X}^\top\mathbf{X}$

---

## D√©composition en valeurs singuli√®res (DVS)

Toute matrice $\mathbf{X} \in \mathbb{R}^{N \times d}$ admet une d√©composition :

$$\mathbf{X} = \mathbf{U}\mathbf{D}\mathbf{V}^\top$$

| Matrice | Dimension | Propri√©t√©s | Interpr√©tation |
|---------|-----------|------------|----------------|
| $\mathbf{U}$ | $N \times d$ | Colonnes orthonormales | Directions dans l'espace des observations |
| $\mathbf{D}$ | $d \times d$ | Diagonale, $d_1 \geq \cdots \geq d_d \geq 0$ | Valeurs singuli√®res (amplitudes) |
| $\mathbf{V}$ | $d \times d$ | Orthogonale | Directions principales (espace des caract√©ristiques) |

**Lien avec les valeurs propres** : Les colonnes de $\mathbf{V}$ sont les vecteurs propres de $\mathbf{X}^\top\mathbf{X}$, et $d_j^2$ sont les valeurs propres correspondantes.

---

## G√©om√©trie de la DVS : ellipse des donn√©es

![w:650](../_static/svd_ellipse_geometry.png)

Les **vecteurs singuliers** $\mathbf{v}_j$ sont les axes naturels du nuage de donn√©es. Les **valeurs singuli√®res** $d_j$ mesurent la **dispersion des donn√©es** le long de chaque axe.

---

## Deux variances : ne pas confondre!

Le mot ¬´ variance ¬ª a **deux sens distincts** :

| Type | D√©finition | Proportionnelle √† | Quand $d_j$ est grand |
|------|------------|-------------------|----------------------|
| **Variance des donn√©es** | Dispersion le long de $\mathbf{v}_j$ | $d_j^2$ | √âlev√©e |
| **Variance d'estimation** | Incertitude sur $\hat{\theta}_j$ | $1/d_j^2$ | Faible |

**Ces deux variances sont inversement reli√©es!**

- Grande dispersion des donn√©es ‚Üí beaucoup d'information ‚Üí estim√© pr√©cis
- Petite dispersion des donn√©es ‚Üí peu d'information ‚Üí estim√© incertain

**Ridge** r√©duit la **variance d'estimation** (incertitude sur $\hat{\boldsymbol{\theta}}$) en r√©tr√©cissant les directions o√π $d_j$ est petit, c'est-√†-dire l√† o√π les donn√©es manquent de dispersion.

---

## Interpr√©tation g√©om√©trique de la DVS

La DVS d√©compose la transformation $\mathbf{X}$ en trois √©tapes :

1. **$\mathbf{V}^\top$** : Rotation dans l'espace des caract√©ristiques (vers les axes principaux)
2. **$\mathbf{D}$** : √âtirement ou compression le long de chaque axe (par $d_j$)
3. **$\mathbf{U}$** : Rotation dans l'espace des observations

| Valeur singuli√®re | Signal | Variance des donn√©es | Variance d'estimation |
|-------------------|--------|---------------------|----------------------|
| $d_j$ grand | Fort | √âlev√©e (donn√©es dispers√©es) | Faible (estim√© pr√©cis) |
| $d_j$ petit | Faible | Faible (peu de dispersion) | √âlev√©e (estim√© incertain) |

**Conditionnement** : Le ratio $\kappa = d_1/d_d$ mesure la difficult√© num√©rique. Si $\kappa$ est grand, $\mathbf{X}^\top\mathbf{X}$ est mal conditionn√©e.

---

## Spectre des valeurs singuli√®res et rang effectif

![w:900](../_static/singular_value_spectrum.png)

Le **rang effectif** : nombre de valeurs singuli√®res significatives (au-dessus du bruit).

---

## Solution MCO via DVS

En utilisant $\mathbf{X} = \mathbf{U}\mathbf{D}\mathbf{V}^\top$, la solution MCO devient :

$$\hat{\boldsymbol{\theta}}_{\text{MCO}} = \mathbf{V}\mathbf{D}^{-1}\mathbf{U}^\top\mathbf{y} = \sum_{j=1}^d \frac{\mathbf{u}_j^\top \mathbf{y}}{d_j} \mathbf{v}_j$$

**D√©composition terme par terme** :
- $\mathbf{u}_j^\top \mathbf{y}$ : Projection de $\mathbf{y}$ sur la $j$-√®me direction
- $1/d_j$ : Normalisation par l'amplitude de cette direction
- $\mathbf{v}_j$ : Direction correspondante dans l'espace des param√®tres

**Probl√®me** : Si $d_j \approx 0$, nous divisons par un petit nombre, ce qui cause une **amplification du bruit**.

---

## Instabilit√© num√©rique de MCO

$$\hat{\boldsymbol{\theta}}_{\text{MCO}} = \sum_{j=1}^d \frac{\mathbf{u}_j^\top \mathbf{y}}{d_j} \mathbf{v}_j$$

| Situation | Cons√©quence |
|-----------|-------------|
| $d_j$ petit | Division par petit nombre, coefficients √©normes |
| Caract√©ristiques corr√©l√©es | Valeurs singuli√®res proches de 0 |
| $d \approx N$ | Matrice $\mathbf{X}^\top\mathbf{X}$ proche de singuli√®re |
| $d > N$ | Infinit√© de solutions (syst√®me sous-d√©termin√©) |

**Exemple** : Si $d_j = 0{,}001$ et $\mathbf{u}_j^\top\mathbf{y} = 0{,}1$, la contribution est $100 \cdot \mathbf{v}_j$. Le bruit est amplifi√© 1000 fois.

**Solution** : R√©gularisation (Ridge), qui p√©nalise les directions √† faible signal.

---

<!-- footer: "üìñ Chapitre 4 : G√©n√©ralisation et s√©lection de mod√®les" -->

## Expansion de caract√©ristiques

Pour capturer des relations non lin√©aires tout en gardant un mod√®le lin√©aire dans les param√®tres, nous transformons les entr√©es.

**Trois familles de mod√®les** de complexit√© croissante :

| Famille | Mod√®le | Caract√©ristiques |
|---------|--------|------------------|
| Lin√©aire | $f(\mathbf{x}) = \boldsymbol{\theta}^\top \mathbf{x}$ | Fix√©es, simples |
| Expansion | $f(\mathbf{x}) = \boldsymbol{\theta}^\top \boldsymbol{\phi}(\mathbf{x})$ | Fix√©es, complexes |
| R√©seaux de neurones | $f(\mathbf{x}) = f_K(\cdots f_1(\mathbf{x}))$ | **Apprises** |

L'expansion de caract√©ristiques utilise une transformation $\boldsymbol{\phi}: \mathbb{R}^d \to \mathbb{R}^D$ non lin√©aire fix√©e √† l'avance.

---

## R√©gression polynomiale

En **r√©gression polynomiale**, nous appliquons une fonction $\phi: \mathbb{R} \to \mathbb{R}^{k+1}$ :

$$\phi(x) = [1, x, x^2, \ldots, x^k]$$

La pr√©diction devient $f(x; \boldsymbol{\theta}) = \boldsymbol{\theta}^\top \phi(x) = \theta_0 + \theta_1 x + \cdots + \theta_k x^k$.

**Polynomiale en $x$, mais lin√©aire en $\boldsymbol{\theta}$** : m√™mes algorithmes (MCO, Ridge)!

| Degr√© $k$ | Comportement |
|-----------|--------------|
| $k = 1$ | Droite |
| $k$ mod√©r√© | Capture la structure |
| $k = N-1$ | Interpole exactement les $N$ points |

Le degr√© $k$ contr√¥le la **capacit√©** du mod√®le.

---

## Intuition g√©om√©trique : s√©parer l'ins√©parable

![w:900](../_static/feature_expansion_3d.gif)

En projetant dans un espace de dimension sup√©rieure, des donn√©es **non lin√©airement s√©parables** deviennent **lin√©airement s√©parables**.

---

## L'√©cart de g√©n√©ralisation

$$\text{√âcart} = \underbrace{\mathcal{R}(f)}_{\text{Erreur sur nouvelles donn√©es}} - \underbrace{\hat{\mathcal{R}}(f; \mathcal{D}_{\text{train}})}_{\text{Erreur d'entra√Ænement}}$$

| Diagnostic | Erreur entra√Ænement | Erreur test | Probl√®me |
|------------|---------------------|-------------|----------|
| Sous-apprentissage | √âlev√©e | √âlev√©e | Mod√®le trop simple |
| Bon ajustement | Faible | Faible | Correct |
| **Surapprentissage** | **Tr√®s faible** | **√âlev√©e** | **Mod√®le m√©morise le bruit** |

Le surapprentissage survient quand le mod√®le s'ajuste aux **particularit√©s** de l'√©chantillon (y compris le bruit) plut√¥t qu'aux **r√©gularit√©s** sous-jacentes.

---

## Illustration : r√©gression polynomiale

![w:800](../_static/polynomial_overfitting.png)

**Degr√© 1** : sous-apprentissage (ne capture pas la courbure). **Degr√© 3** : bon compromis. **Degr√© 15** : surapprentissage (oscillations, m√©morise le bruit).

---

## Courbes d'erreur : le compromis en action

![w:750](../_static/bias_variance_tradeoff.png)

L'erreur d'entra√Ænement ‚Üì avec la complexit√©. L'erreur de test forme un **U** : elle diminue puis augmente.

---

## D√©composition biais-variance : d√©rivation

Rappel : le mod√®le g√©n√©ratif est $y = f^*(\mathbf{x}) + \epsilon$ avec $\mathbb{E}[\epsilon] = 0$, $\text{Var}(\epsilon) = \sigma^2$.

**Variables al√©atoires** :
- $f^*(\mathbf{x})$ : **fixe** (vraie fonction, d√©terministe)
- $\epsilon$ : **al√©atoire** (bruit d'observation)
- $\hat{f}(\mathbf{x})$ : **al√©atoire** via $\mathcal{D}$ (diff√©rents √©chantillons ‚Üí diff√©rentes fonctions apprises ‚Üí diff√©rentes pr√©dictions)

L'esp√©rance $\mathbb{E}[\hat{f}(\mathbf{x})]$ moyenne sur tous les $\mathcal{D}$ possibles. D√©composons l'erreur :

$$\mathbb{E}_{\mathcal{D}, \epsilon}[(\hat{f}(\mathbf{x}) - y)^2] = \mathbb{E}[(\hat{f}(\mathbf{x}) - f^*(\mathbf{x}) - \epsilon)^2]$$

En d√©veloppant et utilisant $\mathbb{E}[\epsilon] = 0$ et l'ind√©pendance de $\epsilon$ et $\hat{f}$ :

$$= \mathbb{E}[(\hat{f}(\mathbf{x}) - f^*(\mathbf{x}))^2] + \sigma^2$$

---

## D√©composition biais-variance : suite

Ajoutons et retranchons $\mathbb{E}[\hat{f}(\mathbf{x})]$ dans le premier terme :

$$\mathbb{E}[(\hat{f}(\mathbf{x}) - f^*(\mathbf{x}))^2] = \mathbb{E}[(\hat{f}(\mathbf{x}) - \mathbb{E}[\hat{f}(\mathbf{x})] + \mathbb{E}[\hat{f}(\mathbf{x})] - f^*(\mathbf{x}))^2]$$

$$= \underbrace{\mathbb{E}[(\hat{f}(\mathbf{x}) - \mathbb{E}[\hat{f}(\mathbf{x})])^2]}_{\text{Var}(\hat{f}(\mathbf{x}))} + \underbrace{(\mathbb{E}[\hat{f}(\mathbf{x})] - f^*(\mathbf{x}))^2}_{\text{Biais}^2}$$

$$\boxed{\text{Erreur} = \text{Biais}^2(\hat{f}(\mathbf{x})) + \text{Var}(\hat{f}(\mathbf{x})) + \sigma^2}$$

| Terme | Signification | D√©pend de |
|-------|---------------|-----------|
| Biais¬≤ | √âcart syst√©matique √† $f^*$ | Classe $\mathcal{H}$ (trop restrictive?) |
| Variance | Sensibilit√© √† l'√©chantillon | Complexit√© et taille $N$ |
| $\sigma^2$ | Bruit irr√©ductible | Donn√©es uniquement |

---

## Le compromis biais-variance

| Complexit√© du mod√®le | Biais | Variance | Erreur totale |
|---------------------|-------|----------|---------------|
| Trop simple | ‚Üë‚Üë | ‚Üì | √âlev√©e (sous-apprentissage) |
| Optimale | ‚Üì | ‚Üì | **Minimale** |
| Trop complexe | ‚Üì | ‚Üë‚Üë | √âlev√©e (surapprentissage) |

**Lien avec le pr√©dicteur de Bayes** : Si $f^* = \mathbb{E}[y|\mathbf{x}]$, le biais mesure √† quel point notre classe $\mathcal{H}$ peut approcher cette fonction.

**Lien avec la DVS** : Les directions √† petites valeurs singuli√®res (faible variance des donn√©es) ont une grande **variance d'estimation**, amplifiant le bruit. Ridge cible pr√©cis√©ment ces directions.

---

<!-- footer: "üìñ Chapitre 2 : R√©gression lin√©aire (section Ridge)" -->

## Besoin de r√©gularisation

**Probl√®mes avec MCO sans r√©gularisation** :
1. $\mathbf{X}^\top\mathbf{X}$ peut √™tre **singuli√®re** ou **mal conditionn√©e**
2. Coefficients **instables** quand les caract√©ristiques sont corr√©l√©es
3. **Surapprentissage** avec beaucoup de caract√©ristiques ($d$ grand)

**Solution, la r√©gularisation** : P√©naliser la ¬´ complexit√© ¬ª du mod√®le

$$\hat{\boldsymbol{\theta}} = \arg\min_{\boldsymbol{\theta}} \left[ \underbrace{\hat{\mathcal{R}}(\boldsymbol{\theta})}_{\text{Ajustement aux donn√©es}} + \underbrace{\lambda \cdot C(\boldsymbol{\theta})}_{\text{P√©nalit√© de complexit√©}} \right]$$

Le param√®tre $\lambda > 0$ contr√¥le le compromis biais-variance.

---

## Objectif Ridge (r√©gularisation L2)

Ajouter une p√©nalit√© sur la **norme L2** des param√®tres :

$$\hat{\boldsymbol{\theta}}_{\text{ridge}} = \arg\min_{\boldsymbol{\theta}} \left[ \|\mathbf{y} - \mathbf{X}\boldsymbol{\theta}\|_2^2 + \lambda \|\boldsymbol{\theta}\|_2^2 \right]$$

| $\lambda$ | Effet | R√©sultat |
|-----------|-------|----------|
| $\lambda = 0$ | Pas de p√©nalit√© | Solution MCO |
| $\lambda$ petit | L√©g√®re r√©gularisation | R√©duction de la variance |
| $\lambda$ grand | Forte r√©gularisation | Coefficients tendent vers 0 |
| $\lambda \to \infty$ | P√©nalit√© dominante | $\boldsymbol{\theta} \to \mathbf{0}$ |

**Interpr√©tation** : Nous cherchons un compromis entre bien ajuster les donn√©es et garder des coefficients raisonnables.

---

## Solution analytique Ridge

Gradient de l'objectif :
$$\nabla_{\boldsymbol{\theta}} \left[ \|\mathbf{y} - \mathbf{X}\boldsymbol{\theta}\|^2 + \lambda\|\boldsymbol{\theta}\|^2 \right] = -2\mathbf{X}^\top(\mathbf{y} - \mathbf{X}\boldsymbol{\theta}) + 2\lambda\boldsymbol{\theta}$$

Condition d'optimalit√© (gradient nul) :
$$\mathbf{X}^\top\mathbf{X}\boldsymbol{\theta} + \lambda\boldsymbol{\theta} = \mathbf{X}^\top\mathbf{y}$$
$$(\mathbf{X}^\top\mathbf{X} + \lambda\mathbf{I})\boldsymbol{\theta} = \mathbf{X}^\top\mathbf{y}$$

$$\boxed{\hat{\boldsymbol{\theta}}_{\text{ridge}} = (\mathbf{X}^\top\mathbf{X} + \lambda\mathbf{I})^{-1}\mathbf{X}^\top\mathbf{y}}$$

L'ajout de $\lambda\mathbf{I}$ **garantit l'inversibilit√©** et am√©liore le conditionnement.

---

## G√©om√©trie de Ridge : formulation contrainte

![w:600](../_static/ridge_geometry.gif)

La figure montre la formulation **contrainte** √©quivalente :
$$\min_{\boldsymbol{\theta}} \|\mathbf{y} - \mathbf{X}\boldsymbol{\theta}\|^2 \quad \text{sous contrainte} \quad \|\boldsymbol{\theta}\|^2 \leq t$$

- **Ellipses** : Lignes de niveau de la SCR
- **Cercle** : R√©gion admissible $\|\boldsymbol{\theta}\|^2 \leq t$
- **Solution** : Plus petite SCR compatible avec la contrainte

La formulation p√©nalis√©e $\text{SCR} + \lambda\|\boldsymbol{\theta}\|^2$ est le lagrangien; chaque $\lambda$ correspond √† un $t$.

---

## Solution Ridge via DVS

Avec $\mathbf{X} = \mathbf{U}\mathbf{D}\mathbf{V}^\top$, la solution Ridge devient :

$$\hat{\boldsymbol{\theta}}_{\text{ridge}} = \sum_{j=1}^d \underbrace{\frac{d_j^2}{d_j^2 + \lambda}}_{\text{facteur } \in [0,1]} \cdot \frac{\mathbf{u}_j^\top \mathbf{y}}{d_j} \cdot \mathbf{v}_j$$

**Facteur de r√©tr√©cissement** $\frac{d_j^2}{d_j^2 + \lambda}$ :

| Valeur singuli√®re | Facteur | Effet |
|-------------------|---------|-------|
| $d_j$ grand (signal fort) | $\approx 1$ | Peu de r√©tr√©cissement |
| $d_j$ petit (bruit) | $\approx 0$ | Fort r√©tr√©cissement |
| $d_j = \sqrt{\lambda}$ | $0{,}5$ | R√©tr√©cissement moyen |

---

## De Ridge √† l'ACP : deux philosophies

| Approche | Traitement des directions bruit√©es | Type |
|----------|-----------------------------------|------|
| **Ridge** | R√©tr√©cit (seuillage doux) | Continue : garde tout, p√©nalise |
| **ACP** | √âlimine (seuillage dur) | Discr√®te : garde $k$, ignore le reste |

**Analyse en composantes principales (ACP)** : Garder seulement les $k$ premi√®res directions :
$$\mathbf{z}_n = \mathbf{V}_k^\top (\mathbf{x}_n - \bar{\mathbf{x}}) \in \mathbb{R}^k$$

Ridge est appropri√©e pour la r√©gression supervis√©e. L'ACP est appropri√©e pour la r√©duction de dimension non supervis√©e.

---

<!-- footer: "üìñ Chapitre 5 : Le cadre probabiliste" -->

## L'approche bay√©sienne

Plut√¥t que de choisir une perte arbitraire, **mod√©lisons** explicitement la g√©n√©ration des donn√©es :

$$p(\boldsymbol{\theta} | \mathcal{D}) = \frac{p(\boldsymbol{\theta}) \cdot p(\mathcal{D} | \boldsymbol{\theta})}{p(\mathcal{D})}$$

| Terme | Nom | Signification |
|-------|-----|---------------|
| $p(\boldsymbol{\theta})$ | **A priori** | Croyances avant de voir les donn√©es |
| $p(\mathcal{D} \| \boldsymbol{\theta})$ | **Vraisemblance** | Probabilit√© des donn√©es pour un $\boldsymbol{\theta}$ |
| $p(\boldsymbol{\theta} \| \mathcal{D})$ | **A posteriori** | Croyances mises √† jour |
| $p(\mathcal{D})$ | **√âvidence** | Constante de normalisation |

L'a posteriori combine notre connaissance pr√©alable avec l'information des donn√©es.

---

## Distribution pr√©dictive bay√©sienne

L'approche **compl√®tement bay√©sienne** moyenne sur tous les param√®tres possibles :

$$p(y | \mathbf{x}, \mathcal{D}) = \int p(y | \mathbf{x}, \boldsymbol{\theta}) \cdot p(\boldsymbol{\theta} | \mathcal{D}) \, d\boldsymbol{\theta}$$

Cette **distribution pr√©dictive a posteriori** :
- Int√®gre l'**incertitude sur les param√®tres** dans la pr√©diction
- Ne s'engage pas sur une valeur unique de $\boldsymbol{\theta}$
- Donne des **intervalles de confiance** naturels

**Avantages** : Quantification de l'incertitude, robustesse, pas de surapprentissage.

---

## Probl√®me : l'int√©grale est intraitable

$$p(y | \mathbf{x}, \mathcal{D}) = \int p(y | \mathbf{x}, \boldsymbol{\theta}) \cdot p(\boldsymbol{\theta} | \mathcal{D}) \, d\boldsymbol{\theta}$$

**En haute dimension**, cette int√©grale est **impossible √† calculer** analytiquement :
- Espace des param√®tres de dimension $d$, int√©gration sur $\mathbb{R}^d$
- Pas de forme ferm√©e en g√©n√©ral

**Solution pragmatique** : Utiliser des **estimateurs ponctuels** :

| Estimateur | Principe |
|------------|----------|
| **EMV** (maximum de vraisemblance) | $\hat{\boldsymbol{\theta}} = \arg\max p(\mathcal{D}\|\boldsymbol{\theta})$ |
| **MAP** (maximum a posteriori) | $\hat{\boldsymbol{\theta}} = \arg\max p(\boldsymbol{\theta}\|\mathcal{D})$ |

---

## Mod√®le probabiliste : bruit gaussien

![w:650](../_static/regression_scedasticity.gif)

Nous mod√©lisons : $y = \boldsymbol{\theta}^\top\mathbf{x} + \epsilon$, o√π $\epsilon \sim \mathcal{N}(0, \sigma^2)$

Chaque observation $y$ suit une gaussienne centr√©e sur la droite de r√©gression.

---

## Maximum de vraisemblance (EMV)

L'EMV trouve les param√®tres qui **maximisent la probabilit√© d'observer les donn√©es** :

$$\hat{\boldsymbol{\theta}}_{\text{EMV}} = \arg\max_{\boldsymbol{\theta}} \prod_{i=1}^N p(y_i | \mathbf{x}_i; \boldsymbol{\theta})$$

En passant au log (transforme le produit en somme) :
$$\hat{\boldsymbol{\theta}}_{\text{EMV}} = \arg\min_{\boldsymbol{\theta}} \underbrace{-\sum_{i=1}^N \log p(y_i | \mathbf{x}_i; \boldsymbol{\theta})}_{\text{Log-vraisemblance n√©gative}}$$

**Sous bruit gaussien** $p(y|\mathbf{x},\boldsymbol{\theta}) = \mathcal{N}(y | \boldsymbol{\theta}^\top\mathbf{x}, \sigma^2)$ :
$$\text{LVN} = \frac{N}{2}\log(2\pi\sigma^2) + \frac{1}{2\sigma^2}\sum_i (y_i - \boldsymbol{\theta}^\top\mathbf{x}_i)^2 \propto \text{SCR}$$

**EMV = MCO** sous l'hypoth√®se de bruit gaussien.

---

## Maximum a posteriori (MAP)

Le MAP trouve le **mode** de la distribution a posteriori :

$$\hat{\boldsymbol{\theta}}_{\text{MAP}} = \arg\max_{\boldsymbol{\theta}} p(\boldsymbol{\theta} | \mathcal{D}) = \arg\max_{\boldsymbol{\theta}} p(\mathcal{D} | \boldsymbol{\theta}) \cdot p(\boldsymbol{\theta})$$

En passant au log :
$$\hat{\boldsymbol{\theta}}_{\text{MAP}} = \arg\min_{\boldsymbol{\theta}} \left[ \underbrace{-\log p(\mathcal{D} | \boldsymbol{\theta})}_{\text{LVN (ajustement)}} + \underbrace{(-\log p(\boldsymbol{\theta}))}_{\text{P√©nalit√© (a priori)}} \right]$$

L'a priori devient naturellement un **terme de r√©gularisation**.

- A priori uniforme : $-\log p(\boldsymbol{\theta}) = \text{cst}$, donc MAP = EMV
- A priori gaussien : $-\log p(\boldsymbol{\theta}) \propto \|\boldsymbol{\theta}\|^2$, donc MAP = Ridge

---

## Limites de l'EMV : exemple de la pi√®ce

Supposons 3 lancers de pi√®ce, tous face. Quel est l'EMV de $\theta = P(\text{face})$?

$$\mathcal{L}(\theta) = \theta^3 \quad \Rightarrow \quad \hat{\theta}_{\text{EMV}} = \arg\max_{\theta \in [0,1]} \theta^3 = 1$$

L'EMV pr√©dit que la pi√®ce tombe **toujours** sur face!

| Probl√®me | Cause |
|----------|-------|
| Estimation extr√™me | Peu de donn√©es |
| Pas de mod√©ration | A priori uniforme implicite |

**Solution** : Un a priori informatif peut ¬´ tirer ¬ª l'estimation vers des valeurs plus raisonnables.

---

## Lissage de Laplace

Avec un a priori **Beta**(2, 2), l'estimateur MAP devient :

$$\hat{\theta}_{\text{MAP}} = \frac{N_1 + 1}{N_1 + N_0 + 2}$$

Avec 3 faces et 0 pile : $\hat{\theta}_{\text{MAP}} = \frac{3+1}{3+0+2} = \frac{4}{5} = 0{,}8$

| Estimateur | Valeur | Interpr√©tation |
|------------|--------|----------------|
| EMV | 1,0 | 100% face |
| MAP | 0,8 | Plus raisonnable |

C'est comme si nous avions observ√© 1 face et 1 pile suppl√©mentaires avant de commencer.

---

## A priori gaussien et r√©gularisation L2

Supposons un a priori gaussien centr√© (isotrope) :

$$p(\boldsymbol{\theta}) = \mathcal{N}(\boldsymbol{\theta} | \mathbf{0}, \tau^2 \mathbf{I}) = \frac{1}{(2\pi\tau^2)^{d/2}} \exp\left(-\frac{\|\boldsymbol{\theta}\|^2}{2\tau^2}\right)$$

Le log de l'a priori est :
$$-\log p(\boldsymbol{\theta}) = \frac{d}{2}\log(2\pi\tau^2) + \frac{1}{2\tau^2}\|\boldsymbol{\theta}\|^2$$

La partie qui d√©pend de $\boldsymbol{\theta}$ est $\frac{1}{2\tau^2}\|\boldsymbol{\theta}\|^2$, une **p√©nalit√© L2**.

**Interpr√©tation** : L'a priori gaussien encode notre croyance que les coefficients sont probablement ¬´ petits ¬ª (proches de 0).

---

## MAP avec a priori gaussien = Ridge

Avec vraisemblance gaussienne ($\sigma^2$) et a priori gaussien ($\tau^2$) :

$$\hat{\boldsymbol{\theta}}_{\text{MAP}} = \arg\min_{\boldsymbol{\theta}} \left[ \frac{1}{2\sigma^2}\|\mathbf{y} - \mathbf{X}\boldsymbol{\theta}\|^2 + \frac{1}{2\tau^2}\|\boldsymbol{\theta}\|^2 \right]$$

En comparant avec Ridge $\|\mathbf{y} - \mathbf{X}\boldsymbol{\theta}\|^2 + \lambda\|\boldsymbol{\theta}\|^2$ :

$$\boxed{\lambda = \frac{\sigma^2}{\tau^2}}$$

| Param√®tre | Interpr√©tation | Effet sur $\lambda$ |
|-----------|----------------|---------------------|
| $\tau^2$ grand | A priori large | $\lambda$ petit, peu de r√©gularisation |
| $\tau^2$ petit | A priori concentr√© | $\lambda$ grand, forte r√©gularisation |

---

## Synth√®se : deux langages, m√™mes algorithmes

| Perspective d√©cisionnelle | Perspective probabiliste |
|---------------------------|--------------------------|
| Perte quadratique $(y-\hat{y})^2$ | Bruit gaussien $\mathcal{N}(y\|\boldsymbol{\theta}^\top\mathbf{x}, \sigma^2)$ |
| Minimiser SCR | Maximum de vraisemblance (EMV) |
| **Solution MCO** | **Solution MCO** |
| + R√©gularisation L2 $\lambda\|\boldsymbol{\theta}\|^2$ | + A priori gaussien $\mathcal{N}(\mathbf{0}, \tau^2\mathbf{I})$ |
| **R√©gression Ridge** | **Maximum a posteriori (MAP)** |

Les deux perspectives sont **√©quivalentes** math√©matiquement, mais offrent des √©clairages compl√©mentaires :
- **D√©cisionnelle** : Comment construire l'algorithme
- **Probabiliste** : Pourquoi ces choix sont raisonnables

---

<!-- _class: lead -->

# Classification lin√©aire

De la r√©gression √† la classification

---

<!-- footer: "üìñ Chapitre 3 : Classification lin√©aire" -->

## De la r√©gression √† la classification

| R√©gression | Classification |
|------------|----------------|
| $y \in \mathbb{R}$ (continu) | $y \in \{0, 1, \ldots, C-1\}$ (discret) |
| Pr√©dire une valeur | Pr√©dire une cat√©gorie |
| Perte quadratique | Perte 0-1 |
| Bruit gaussien | Distribution de Bernoulli/cat√©gorielle |

**Probl√®me** : $\boldsymbol{\theta}^\top \mathbf{x}$ peut produire n'importe quelle valeur r√©elle, pas une probabilit√© dans $[0, 1]$.

**Solution** : Transformer le score par une fonction qui ¬´ √©crase ¬ª vers $[0, 1]$.

---

## La fonction sigmo√Øde

![w:800](../_static/sigmoid_approximation.gif)

$$\sigma(a) = \frac{1}{1 + e^{-a}}$$

La sigmo√Øde transforme un score r√©el en probabilit√©. Elle approxime la fonction √©chelon tout en restant **diff√©rentiable**.

---

## R√©gression logistique binaire

**Mod√®le** : La probabilit√© de la classe positive est

$$p(y = 1 | \mathbf{x}; \boldsymbol{\theta}) = \sigma(\boldsymbol{\theta}^\top \mathbf{x}) = \frac{1}{1 + e^{-\boldsymbol{\theta}^\top \mathbf{x}}}$$

| Valeur de $\boldsymbol{\theta}^\top \mathbf{x}$ | Probabilit√© $p(y=1)$ | Interpr√©tation |
|------------------------------------------------|---------------------|----------------|
| $\ll 0$ | $\approx 0$ | Confiant classe 0 |
| $= 0$ | $0{,}5$ | √âquiprobable |
| $\gg 0$ | $\approx 1$ | Confiant classe 1 |

La distribution conditionnelle suit une loi de **Bernoulli** :
$$p(y | \mathbf{x}; \boldsymbol{\theta}) = \mu^y (1 - \mu)^{1-y}, \quad \mu = \sigma(\boldsymbol{\theta}^\top \mathbf{x})$$

---

## Fronti√®re de d√©cision

Pour classifier, nous pr√©disons la classe la plus probable :

$$\hat{y} = \mathbb{1}(\boldsymbol{\theta}^\top \mathbf{x} > 0)$$

La **fronti√®re de d√©cision** est l'ensemble des points o√π les deux classes sont √©quiprobables :

$$\{\mathbf{x} : \boldsymbol{\theta}^\top \mathbf{x} = 0\}$$

C'est un **hyperplan** dans l'espace des entr√©es :
- En 2D : une droite
- En 3D : un plan
- Le vecteur $\boldsymbol{\theta}$ est perpendiculaire √† cet hyperplan

---

## Maximum de vraisemblance pour Bernoulli

Sous l'hypoth√®se i.i.d., la vraisemblance est :

$$\mathcal{L}(\boldsymbol{\theta}) = \prod_{i=1}^N \mu_i^{y_i} (1 - \mu_i)^{1-y_i}$$

La log-vraisemblance n√©gative (LVN) est :

$$\text{LVN}(\boldsymbol{\theta}) = -\frac{1}{N} \sum_{i=1}^N \left[ y_i \log \mu_i + (1 - y_i) \log(1 - \mu_i) \right]$$

Cette quantit√© est l'**entropie crois√©e binaire**. Ce n'est pas un choix arbitraire : elle d√©coule du maximum de vraisemblance!

---

## Gradient de l'entropie crois√©e

Le gradient a une forme remarquablement simple :

$$\nabla_{\boldsymbol{\theta}} \text{LVN}(\boldsymbol{\theta}) = \frac{1}{N} \sum_{i=1}^N (\mu_i - y_i) \mathbf{x}_i = \frac{1}{N} \mathbf{X}^\top (\boldsymbol{\mu} - \mathbf{y})$$

| Terme | Signification |
|-------|---------------|
| $\mu_i - y_i$ | Erreur de pr√©diction pour l'exemple $i$ |
| $\mathbf{x}_i$ | Direction de mise √† jour |

**Comparaison avec MCO** : Le gradient de la SCR est $\frac{1}{N}\mathbf{X}^\top(\mathbf{X}\boldsymbol{\theta} - \mathbf{y})$.

Forme similaire, mais pas de solution analytique (√©quation non lin√©aire en $\boldsymbol{\theta}$).

---

## Classification multiclasse : softmax

Pour $C$ classes, nous g√©n√©ralisons la sigmo√Øde par la fonction **softmax** :

$$p(y = c | \mathbf{x}; \boldsymbol{\Theta}) = \frac{e^{a_c}}{\sum_{j=1}^{C} e^{a_j}}$$

o√π $\mathbf{a} = \boldsymbol{\Theta} \mathbf{x}$ est le vecteur de **logits** (un score par classe).

| Propri√©t√© | Valeur |
|-----------|--------|
| $\text{softmax}(\mathbf{a})_c$ | $> 0$ pour tout $c$ |
| $\sum_c \text{softmax}(\mathbf{a})_c$ | $= 1$ |

La perte est l'**entropie crois√©e cat√©gorielle** : $-\log p(y = y_i | \mathbf{x}_i)$.

Pour $C = 2$, le softmax se r√©duit √† la sigmo√Øde.

---

## Descente de gradient stochastique (SGD)

Contrairement √† MCO, pas de solution analytique. Nous utilisons la **descente de gradient** :

$$\boldsymbol{\theta}_{t+1} = \boldsymbol{\theta}_t - \eta \nabla_{\boldsymbol{\theta}} \text{LVN}(\boldsymbol{\theta}_t)$$

**Probl√®me** : Calculer le gradient exact requiert de parcourir tous les $N$ exemples.

**SGD** : Utiliser un **mini-lot** $\mathcal{B}_t$ de quelques dizaines d'exemples :

$$\boldsymbol{\theta}_{t+1} = \boldsymbol{\theta}_t - \eta \cdot \frac{1}{|\mathcal{B}_t|} \sum_{i \in \mathcal{B}_t} (\mu_i - y_i) \mathbf{x}_i$$

Cette estimation est **non biais√©e** : en esp√©rance, elle √©gale le vrai gradient.

---

## Synth√®se : r√©gression vs classification

| | R√©gression | Classification |
|-|------------|----------------|
| **Mod√®le probabiliste** | $\mathcal{N}(y \| \boldsymbol{\theta}^\top\mathbf{x}, \sigma^2)$ | $\text{Ber}(y \| \sigma(\boldsymbol{\theta}^\top\mathbf{x}))$ |
| **Perte (LVN)** | Somme des carr√©s | Entropie crois√©e |
| **Gradient** | $\mathbf{X}^\top(\mathbf{X}\boldsymbol{\theta} - \mathbf{y})$ | $\mathbf{X}^\top(\boldsymbol{\mu} - \mathbf{y})$ |
| **Solution** | Analytique (MCO) | It√©rative (SGD) |
| **R√©gularisation** | Ridge ($+ \lambda\|\boldsymbol{\theta}\|^2$) | Ridge ($+ \lambda\|\boldsymbol{\theta}\|^2$) |

Le cadre probabiliste unifie les deux : le choix du mod√®le (gaussien vs Bernoulli) d√©termine la perte optimale.

---

<!-- footer: "" -->

## R√©sum√©

| Concept | Id√©e cl√© |
|---------|----------|
| **MRE** | Minimiser l'erreur d'entra√Ænement comme approximation du vrai risque |
| **MCO/DVS** | Solution analytique, instabilit√© pour petites valeurs singuli√®res |
| **Expansion** | $\phi(x) = [1, x, x^2, \ldots]$ pour capturer des relations non lin√©aires |
| **Biais-variance** | Mod√®le simple = biais √©lev√©; complexe = variance √©lev√©e |
| **Ridge** | R√©gularisation L2 = a priori gaussien (MAP) |
| **Classification** | Sigmo√Øde/softmax + entropie crois√©e + SGD |

Le cadre probabiliste **unifie** r√©gression et classification : le mod√®le de bruit d√©termine la perte.

---

<!-- _class: lead -->

# Questions?

**Exercices recommand√©s** :
- Exercice 1 (ch4) : Expansion de caract√©ristiques
- Exercice 3 (ch4) : D√©composition biais-variance empirique
- Exercice 5 (ch5) : MAP avec a priori gaussien et Ridge
- Exercice 2 (ch3) : R√©gularisation de la r√©gression logistique
